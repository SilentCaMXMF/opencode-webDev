name: Performance Testing & Monitoring

on:
  push:
    branches:
      - main
      - develop
    paths:
      - '**/*.js'
      - '**/*.css'
      - '**/*.html'
      - 'cypress/**/*'
      - 'playwright/**/*'
  pull_request:
    branches:
      - main
      - develop
  schedule:
    # Run performance tests daily at 3 AM UTC
    - cron: '0 3 * * *'
  workflow_dispatch:
    inputs:
      test_type:
        description: 'Test type'
        required: true
        default: 'all'
        type: choice
        options:
          - all
          - lighthouse
          - web-vitals
          - bundle-analysis
          - load-testing

permissions:
  contents: read
  pull-requests: write

env:
  NODE_VERSION: '20.x'

jobs:
  lighthouse-audit:
    name: Lighthouse Performance Audit
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install Dependencies
        run: npm ci

      - name: Start Test Server
        run: |
          npm run serve &
          sleep 15

      - name: Run Lighthouse CI
        uses: treosh/lighthouse-ci-action@v10
        with:
          urls: |
            http://localhost:3000
            http://localhost:3000/#summary-section
            http://localhost:3000/#skills-section
          uploadArtifacts: true
          temporaryPublicStorage: true
          budgetPath: ./.opencode/workflows/config/lighthouse-budget.json

      - name: Check Lighthouse Scores
        id: lighthouse-check
        run: |
          for report in lighthouse-report-*.json; do
            PERFORMANCE=$(cat $report | jq '.categories.performance.score * 100')
            ACCESSIBILITY=$(cat $report | jq '.categories.accessibility.score * 100')
            BEST_PRACTICES=$(cat $report | jq '.categories.best-practices.score * 100')
            SEO=$(cat $report | jq '.categories.seo.score * 100')

            echo "Checking $report:"
            echo "Performance: $PERFORMANCE"
            echo "Accessibility: $ACCESSIBILITY"
            echo "Best Practices: $BEST_PRACTICES"
            echo "SEO: $SEO"

            # Quality gates
            FAILED=false
            if (( $(echo "$PERFORMANCE < 90" | bc -l) )); then
              echo "‚ùå Performance score ($PERFORMANCE) below threshold (90)"
              FAILED=true
            else
              echo "‚úÖ Performance score: $PERFORMANCE"
            fi

            if (( $(echo "$ACCESSIBILITY < 95" | bc -l) )); then
              echo "‚ùå Accessibility score ($ACCESSIBILITY) below threshold (95)"
              FAILED=true
            else
              echo "‚úÖ Accessibility score: $ACCESSIBILITY"
            fi

            if (( $(echo "$BEST_PRACTICES < 90" | bc -l) )); then
              echo "‚ùå Best Practices score ($BEST_PRACTICES) below threshold (90)"
              FAILED=true
            else
              echo "‚úÖ Best Practices score: $BEST_PRACTICES"
            fi

            if (( $(echo "$SEO < 90" | bc -l) )); then
              echo "‚ùå SEO score ($SEO) below threshold (90)"
              FAILED=true
            else
              echo "‚úÖ SEO score: $SEO"
            fi

            if [ "$FAILED" = true ]; then
              exit 1
            fi
          done

      - name: Upload Lighthouse Reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: lighthouse-reports
          path: |
            .lighthouseci/
            lighthouse-report-*.json
          retention-days: 30

      - name: Comment PR with Lighthouse Results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const reportFile = 'lighthouse-report-localhost-3000.json';
            if (fs.existsSync(reportFile)) {
              const report = JSON.parse(fs.readFileSync(reportFile, 'utf8'));

              const perf = (report.categories.performance.score * 100).toFixed(0);
              const acc = (report.categories.accessibility.score * 100).toFixed(0);
              const bp = (report.categories.bestPractices.score * 100).toFixed(0);
              const seo = (report.categories.seo.score * 100).toFixed(0);

              const emoji = (score) => score >= 90 ? 'üü¢' : score >= 70 ? 'üü°' : 'üî¥';

              const perfEmoji = score => score >= 90 ? 'üü¢' : score >= 70 ? 'üü°' : 'üî¥';
              const comment = `## üöÄ Lighthouse Performance Report\n\n| Metric | Score | Status |\n|--------|-------|--------|\n| Performance | ${perf} | ${perfEmoji(perf)} |\n| Accessibility | ${acc} | ${perfEmoji(acc)} |\n| Best Practices | ${bp} | ${perfEmoji(bp)} |\n| SEO | ${seo} | ${perfEmoji(seo)} |\n\n### Performance Metrics\n\n- First Contentful Paint: ${report.audits['first-contentful-paint'].displayValue}\n- Speed Index: ${report.audits['speed-index'].displayValue}\n- Largest Contentful Paint: ${report.audits['largest-contentful-paint'].displayValue}\n- Time to Interactive: ${report.audits['interactive'].displayValue}\n- Total Blocking Time: ${report.audits['total-blocking-time'].displayValue}\n- Cumulative Layout Shift: ${report.audits['cumulative-layout-shift'].displayValue}`;

              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: comment
              });
            }

  web-vitals:
    name: Core Web Vitals Testing
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install Dependencies
        run: npm ci

      - name: Install Playwright
        run: npx playwright install --with-deps

      - name: Run Web Vitals Tests
        run: npx playwright test --config=playwright.web-vitals.config.ts
        env:
          CI: true

      - name: Check Core Web Vitals Thresholds
        run: |
          if [ -f "web-vitals-results.json" ]; then
            LCP=$(cat web-vitals-results.json | jq '.LCP.value')
            FID=$(cat web-vitals-results.json | jq '.FID.value')
            CLS=$(cat web-vitals-results.json | jq '.CLS.value')

            FAILED=false

            # LCP: Should be <= 2.5s
            if (( $(echo "$LCP > 2500" | bc -l) )); then
              echo "‚ùå LCP ($LCP ms) exceeds threshold (2500 ms)"
              FAILED=true
            else
              echo "‚úÖ LCP: $LCP ms"
            fi

            # FID: Should be <= 100ms
            if (( $(echo "$FID > 100" | bc -l) )); then
              echo "‚ùå FID ($FID ms) exceeds threshold (100 ms)"
              FAILED=true
            else
              echo "‚úÖ FID: $FID ms"
            fi

            # CLS: Should be <= 0.1
            if (( $(echo "$CLS > 0.1" | bc -l) )); then
              echo "‚ùå CLS ($CLS) exceeds threshold (0.1)"
              FAILED=true
            else
              echo "‚úÖ CLS: $CLS"
            fi

            if [ "$FAILED" = true ]; then
              exit 1
            fi
          fi

      - name: Upload Web Vitals Results
        uses: actions/upload-artifact@v4
        with:
          name: web-vitals-results
          path: |
            web-vitals-results.json
            test-results/
          retention-days: 30

  bundle-analysis:
    name: Bundle Size Analysis
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install Dependencies
        run: npm ci

      - name: Build Application
        run: npm run build || true

      - name: Analyze Bundle Size
        run: |
          find dist -type f -name "*.js" -exec du -h {} \; | sort -rh > bundle-sizes.txt

          TOTAL_SIZE=$(find dist -type f -exec du -b {} + | awk '{sum += $1} END {print sum}')
          echo "Total bundle size: $((TOTAL_SIZE / 1024)) KB"

      - name: Check Bundle Size Thresholds
        run: |
          MAX_JS_SIZE=524288  # 512 KB
          MAX_TOTAL_SIZE=1048576  # 1 MB

          LARGEST_JS=$(find dist -type f -name "*.js" -exec du -b {} \; | sort -rn | head -1 | awk '{print $1}')
          TOTAL_SIZE=$(find dist -type f -exec du -b {} + | awk '{sum += $1} END {print sum}')

          if [ "$LARGEST_JS" -gt "$MAX_JS_SIZE" ]; then
            echo "‚ùå Largest JS file ($((LARGEST_JS / 1024)) KB) exceeds threshold ($((MAX_JS_SIZE / 1024)) KB)"
            exit 1
          fi

          if [ "$TOTAL_SIZE" -gt "$MAX_TOTAL_SIZE" ]; then
            echo "‚ùå Total bundle size ($((TOTAL_SIZE / 1024)) KB) exceeds threshold ($((MAX_TOTAL_SIZE / 1024)) KB)"
            exit 1
          fi

      - name: Generate Bundle Report
        run: |
          npm install -g bundlesize
          bundlesize --config ./.opencode/workflows/config/bundlesize.config.json || true

      - name: Upload Bundle Analysis
        uses: actions/upload-artifact@v4
        with:
          name: bundle-analysis
          path: |
            bundle-sizes.txt
            .bundlesize/
          retention-days: 30

      - name: Comment PR with Bundle Changes
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            if (fs.existsSync('bundle-sizes.txt')) {
              const sizes = fs.readFileSync('bundle-sizes.txt', 'utf8');
              const comment = `## üì¶ Bundle Size Analysis\n\n\`\`\`\n${sizes}\n\`\`\``;

              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: comment
              });
            }

  load-testing:
    name: Load Testing
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' || github.event.inputs.test_type == 'load-testing'
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install Dependencies
        run: npm ci

      - name: Install k6
        run: |
          sudo gpg -k
          sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install k6

      - name: Start Test Server
        run: |
          npm run serve &
          sleep 15

      - name: Run Load Test
        run: k6 run ./.opencode/workflows/config/load-test.js
        env:
          BASE_URL: http://localhost:3000

      - name: Upload Load Test Results
        uses: actions/upload-artifact@v4
        with:
          name: load-test-results
          path: |
            load-test-results.json
            load-test-summary.json
          retention-days: 30

  performance-regression:
    name: Performance Regression Detection
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install Dependencies
        run: npm ci

      - name: Checkout Base Branch
        run: |
          git checkout origin/${{ github.base_ref }}

      - name: Run Baseline Performance Test
        run: |
          npm run serve &
          sleep 15
          npm run test:performance
          mv lighthouse-results.json baseline-lighthouse-results.json

      - name: Checkout PR Branch
        run: |
          git checkout ${{ github.sha }}

      - name: Run PR Performance Test
        run: |
          npm run serve &
          sleep 15
          npm run test:performance
          mv lighthouse-results.json pr-lighthouse-results.json

      - name: Compare Performance Results
        run: |
          node ./.opencode/workflows/scripts/compare-performance.js baseline-lighthouse-results.json pr-lighthouse-results.json

      - name: Upload Comparison Results
        uses: actions/upload-artifact@v4
        with:
          name: performance-comparison
          path: |
            baseline-lighthouse-results.json
            pr-lighthouse-results.json
            performance-diff.json
          retention-days: 30

      - name: Comment PR with Performance Changes
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            if (fs.existsSync('performance-diff.json')) {
              const diff = JSON.parse(fs.readFileSync('performance-diff.json', 'utf8'));

              let comment = '## üìä Performance Regression Analysis\n\n';

              if (diff.regressions.length > 0) {
                comment += '### ‚ö†Ô∏è Performance Regressions Detected\n\n';
                diff.regressions.forEach(reg => {
                  comment += `- ${reg.metric}: ${reg.baseline} ‚Üí ${reg.current} (${reg.change}%)\n`;
                });
              } else {
                comment += '### ‚úÖ No Performance Regressions\n\n';
              }

              if (diff.improvements.length > 0) {
                comment += '\n### üöÄ Performance Improvements\n\n';
                diff.improvements.forEach(imp => {
                  comment += `- ${imp.metric}: ${imp.baseline} ‚Üí ${imp.current} (${imp.change}%)\n`;
                });
              }

              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: comment
              });
            }

  performance-summary:
    name: Performance Test Summary
    runs-on: ubuntu-latest
    needs: [lighthouse-audit, web-vitals, bundle-analysis, load-testing, performance-regression]
    if: always()
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Download All Reports
        uses: actions/download-artifact@v4
        with:
          path: performance-reports

      - name: Generate Performance Summary
        run: |
          cat > performance-summary.md << EOF
          # Performance Testing Summary

          ## Test Results

          | Test Suite | Status | Details |
          |-------------|--------|---------|
          | Lighthouse Audit | ${{ needs.lighthouse-audit.result }} | Core Web Vitals & Best Practices |
          | Web Vitals | ${{ needs.web-vitals.result }} | LCP, FID, CLS |
          | Bundle Analysis | ${{ needs.bundle-analysis.result }} | Bundle size optimization |
          | Load Testing | ${{ needs.load-testing.result }} | Scalability testing |
          | Regression Detection | ${{ needs.performance-regression.result }} | Performance changes |

          ## Recommendations

          - Review any failed performance tests
          - Optimize bundle sizes if needed
          - Monitor Web Vitals in production
          - Implement performance budgets
          - Regular performance monitoring

          ## Reports Available

          - Lighthouse audit reports
          - Web Vitals metrics
          - Bundle analysis results
          - Load test results
          - Performance regression analysis

          Testing completed at: $(date -u +%Y-%m-%dT%H:%M:%SZ)
          EOF

      - name: Upload Performance Summary
        uses: actions/upload-artifact@v4
        with:
          name: performance-summary-${{ github.sha }}
          path: performance-summary.md
          retention-days: 90

      - name: Comment Performance Summary
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const summary = fs.readFileSync('performance-summary.md', 'utf8');
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: summary
            });
